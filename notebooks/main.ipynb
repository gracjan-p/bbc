{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-03-13T20:14:37.808349Z",
     "start_time": "2025-03-13T20:14:25.357776Z"
    }
   },
   "source": [
    "import torch\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "torch.cuda.is_available()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-13T20:14:54.128929Z",
     "start_time": "2025-03-13T20:14:54.029759Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('..\\\\datasets\\\\bbc-text.csv')\n",
    "df"
   ],
   "id": "ab1c928658946f1a",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "           category                                               text\n",
       "0              tech  tv future in the hands of viewers with home th...\n",
       "1          business  worldcom boss  left books alone  former worldc...\n",
       "2             sport  tigers wary of farrell  gamble  leicester say ...\n",
       "3             sport  yeading face newcastle in fa cup premiership s...\n",
       "4     entertainment  ocean s twelve raids box office ocean s twelve...\n",
       "...             ...                                                ...\n",
       "2220       business  cars pull down us retail figures us retail sal...\n",
       "2221       politics  kilroy unveils immigration policy ex-chatshow ...\n",
       "2222  entertainment  rem announce new glasgow concert us band rem h...\n",
       "2223       politics  how political squabbles snowball it s become c...\n",
       "2224          sport  souness delight at euro progress boss graeme s...\n",
       "\n",
       "[2225 rows x 2 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tech</td>\n",
       "      <td>tv future in the hands of viewers with home th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>business</td>\n",
       "      <td>worldcom boss  left books alone  former worldc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sport</td>\n",
       "      <td>tigers wary of farrell  gamble  leicester say ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sport</td>\n",
       "      <td>yeading face newcastle in fa cup premiership s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>entertainment</td>\n",
       "      <td>ocean s twelve raids box office ocean s twelve...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2220</th>\n",
       "      <td>business</td>\n",
       "      <td>cars pull down us retail figures us retail sal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2221</th>\n",
       "      <td>politics</td>\n",
       "      <td>kilroy unveils immigration policy ex-chatshow ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2222</th>\n",
       "      <td>entertainment</td>\n",
       "      <td>rem announce new glasgow concert us band rem h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2223</th>\n",
       "      <td>politics</td>\n",
       "      <td>how political squabbles snowball it s become c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2224</th>\n",
       "      <td>sport</td>\n",
       "      <td>souness delight at euro progress boss graeme s...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2225 rows Ã— 2 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "df = df[['headline', 'short_description', 'category']]\n",
    "df"
   ],
   "id": "b6a6ba81b18c8866",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df['headline'] = df['headline'] + df['short_description']",
   "id": "b644b205b3617d1d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "df['headline_len'] = df['headline'].apply(lambda x: len(str(x).split()))\n",
    "df['headline_len']"
   ],
   "id": "3b763d5dd9e88b2e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from matplotlib import pyplot as plt\n",
    "from scipy.stats import hmean\n",
    "import seaborn as sb\n",
    "\n",
    "mid_blue = '#6f93bf'\n",
    "mid_red = '#bf6f6f'\n",
    "\n",
    "min_headline_len = 0\n",
    "max_headline_len = 20\n",
    "\n",
    "headline_mean = df['headline_len'].mean()\n",
    "harmonic_headline_mean = hmean(df['headline_len'])\n",
    "\n",
    "print(\n",
    "    f\"{\"mean\":>20}: {headline_mean:.2f}\",\n",
    "    f\"{\"harmonic mean\":>20}: {harmonic_headline_mean:.2f}\", sep='\\n'\n",
    ")\n",
    "\n",
    "fig, axes = plt.subplots(figsize=(20, 6))\n",
    "\n",
    "axes.set_title('Headline length in words')\n",
    "axes.set_xlabel('Length in words')\n",
    "axes.set_ylabel('Amount of headlines')\n",
    "sb.histplot(df['headline_len'], ax=axes, binwidth=0.5, linewidth=0, color=mid_blue)\n",
    "axes.axvline(x=max_headline_len, color=mid_red, linestyle='--', label='cutoff')\n",
    "\n",
    "plt.tight_layout()"
   ],
   "id": "3c06dc00c3fe99bd",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Beautiful gaussian curve.",
   "id": "ac8b8b546fe8f938"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "headline_cut_to = lambda min, max: (df['headline_len'] > min) & (df['headline_len'] <= max)\n",
    "\n",
    "shorter_than_100 = len(df[headline_cut_to(0, 100)])\n",
    "longer_than_100 = len(df) - len(df[headline_cut_to(0, 100)])\n",
    "\n",
    "print(\n",
    "    \"Amount of headlines\",\n",
    "    f\"  shorter/equal to 100: {shorter_than_100:_}\",\n",
    "    f\"       longer than 100: {longer_than_100:_}\", sep='\\n'\n",
    ")"
   ],
   "id": "f0034c91e90b709a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Since we're going to train our model on most average headline length. <br>\n",
    "I don't see any point to use such small fraction of data. <br>\n",
    "It can be very problematic for training our model. So we can safely remove it."
   ],
   "id": "18e473653ebc87d9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "sorted_categories = df['category'].value_counts().index\n",
    "\n",
    "fig, axes = plt.subplots(figsize=(10, 10))\n",
    "\n",
    "min_label = df['category'].value_counts().min()\n",
    "max_label = df['category'].value_counts().max()\n",
    "\n",
    "print(\n",
    "    f\"min: {min_label}\",\n",
    "    f\"max: {max_label}\", sep='\\n'\n",
    ")\n",
    "\n",
    "sb.countplot(df['category'], order=sorted_categories, color=mid_blue)\n",
    "axes.axvline(x=5_000, color='red', linestyle='--')\n",
    "plt.tight_layout()"
   ],
   "id": "a95982444f62dfaf",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Downsampling",
   "id": "46ce460276b49682"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.utils import resample\n",
    "\n",
    "target = 5_000\n",
    "\n",
    "all_groups = []\n",
    "\n",
    "for label, group in df.groupby('category'):\n",
    "    if len(group) >= target:\n",
    "        resampled_group = group.sample(n=target, random_state=42, replace=False)\n",
    "        all_groups.append(resampled_group)\n",
    "    else:\n",
    "        all_groups.append(group)\n",
    "\n",
    "df = pd.concat(all_groups)"
   ],
   "id": "8b58871c4f7714e7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df['category'].value_counts()",
   "id": "387fc236816dd1b4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "df = df.sample(frac=1).reset_index(drop=True)\n",
    "df.head()"
   ],
   "id": "4cbc34d00af28f27",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### Tokenizing headlines\n",
    "1) shuffle dataset so train and test contain exact amount of each category\n",
    "2) apply tokenizing function"
   ],
   "id": "b2b7a81719452023"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import re\n",
    "\n",
    "def text_clean(text):\n",
    "    result = text.lower()\n",
    "    result = re.sub(r'[^a-zA-Z\\s]', '', result)\n",
    "    result = re.sub(r' +', ' ', result)\n",
    "    return result"
   ],
   "id": "f77f0e45c4d31c80",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "sample = '!@#this is \"a   \"sample! (T*eXt)...'\n",
    "print(\n",
    "    f\"Before: {sample}\",\n",
    "    f\"After: {text_clean(sample)}\", sep='\\n'\n",
    ")"
   ],
   "id": "eab38a029e829af6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "df['headline'] = df['headline'].apply(lambda x: text_clean(str(x)))\n",
    "df"
   ],
   "id": "4207cb766ff51c7e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "df['headline_len'] = df['headline'].apply(lambda x: len(str(x).split()))\n",
    "df['headline_len']"
   ],
   "id": "a1bd03f5a8b5c1ca",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df = df[headline_cut_to(3, 150)]",
   "id": "d256cbbc71a4199b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from collections import Counter\n",
    "\n",
    "tokenized_texts = [text.split() for text in df['headline']]\n",
    "word_counts = Counter([word for text in tokenized_texts\n",
    "                            for word in text])\n",
    "word_counts.most_common(10)"
   ],
   "id": "33611950621db542",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "word_to_idx = {word: i+1 for i, (word, _) in enumerate(word_counts.most_common())}\n",
    "word_to_idx['<PAD>'] = 0\n",
    "idx_to_word = {i: word for word, i in word_to_idx.items()}\n",
    "\n",
    "for i in range(10):\n",
    "    print(idx_to_word[i])"
   ],
   "id": "771b59d4e59f3c3b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "\n",
    "def vectorize_headline(headline):\n",
    "    result = [word_to_idx[w] for w in headline.split()[:100]]\n",
    "    result = np.pad(result, (0, 100 - len(result)))\n",
    "    return result"
   ],
   "id": "84884d2deea88c2f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "vectorize_headline(df['headline'][0])",
   "id": "eb1639c2b4368a92",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "df['headline'] = df['headline'].apply(vectorize_headline)\n",
    "df.head()"
   ],
   "id": "dd7aadb2194e5d70",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Labeling categories",
   "id": "15698fc7a1ee9ee8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "category_to_label = {\n",
    "    cat: i for i, cat in enumerate(sorted_categories)\n",
    "}\n",
    "\n",
    "category_to_label"
   ],
   "id": "dd96e2b1471cfd0d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "df['category'] = df['category'].apply(lambda cat: category_to_label[cat])\n",
    "df.head()"
   ],
   "id": "f73ca69b45d768d4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Data Loaders",
   "id": "6172fd31ee1fb032"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "sequences = df['headline'].to_numpy()\n",
    "labels = df['category'].to_numpy()"
   ],
   "id": "15790474423a4666",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Checking if sequence is paired with label correctly",
   "id": "2d6bd820469786ed"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "mismatches = df[df['headline'] != sequences]\n",
    "if not mismatches.empty:\n",
    "    print(mismatches.iloc[0], sequences[mismatches.index[0]])\n",
    "    \n",
    "mismatches = df[df['category'] != labels]\n",
    "if not mismatches.empty:\n",
    "    print(mismatches.iloc[0], sequences[mismatches.index[0]])"
   ],
   "id": "22dcb8d5332b3340",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "train_size = int(len(df) * 0.7)\n",
    "\n",
    "train_split = sequences[:train_size], labels[:train_size]\n",
    "test_split = sequences[train_size:], labels[train_size:]"
   ],
   "id": "417b8e8867fabc27",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "len(test_split[0]) + len(train_split[0]) == len(df)",
   "id": "30e20eed196b1bee",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "def return_loader(dataset, batch_size=8):\n",
    "\n",
    "    sequences, labels = dataset\n",
    "        \n",
    "    x, y, z = [], [], []\n",
    "    \n",
    "    for sequence, label in zip(sequences, labels):\n",
    "        x.append(sequence)\n",
    "        y.append(label)\n",
    "        z.append(np.count_nonzero(sequence))\n",
    "        \n",
    "    tensor_dataset = TensorDataset(torch.tensor(x).long(),\n",
    "                                   torch.tensor(z).long(),\n",
    "                                   torch.tensor(y).long())\n",
    "    \n",
    "    return DataLoader(tensor_dataset, batch_size=batch_size, drop_last=True)"
   ],
   "id": "f3a811002852d32a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "train_loader  = return_loader(dataset=train_split, batch_size=256)\n",
    "test_loader = return_loader(dataset=test_split, batch_size=256)"
   ],
   "id": "ccda7ec70df24927",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "i = -1\n",
    "\n",
    "for batch in train_loader:\n",
    "    inputs, lengths, targets = batch\n",
    "    \n",
    "    # print(len(lengths))\n",
    "    for i in range(256):\n",
    "        if 0 in lengths[i]:\n",
    "            print(inputs[i], targets[i], lengths[i])"
   ],
   "id": "eb5c1e53dbd4d73e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from torch import nn\n",
    "import torch.nn.utils.rnn as rnn_utils\n",
    "\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_size, hidden_size, output_size, n_layers=1, dropout_rate=0):\n",
    "        super(RNN, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_size, padding_idx=0)\n",
    "        self.rnn = nn.LSTM(input_size=embed_size, hidden_size=hidden_size, dropout=dropout_rate, num_layers=n_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "\n",
    "    def forward(self, x, lengths):\n",
    "        x = self.embedding(x)\n",
    "\n",
    "        x = rnn_utils.pack_padded_sequence(x, lengths, batch_first=True, enforce_sorted=False)\n",
    "    \n",
    "        rnn_out, (hidden, cell) = self.rnn(x)    \n",
    "    \n",
    "        hidden = self.dropout(hidden[-1])\n",
    "        output = self.fc(hidden)\n",
    "        \n",
    "        return output"
   ],
   "id": "478bc40242bb2ad1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from torch import optim\n",
    "\n",
    "def train_model(model, data_loader, n_epochs=1, learning_rate=0.001):\n",
    "    \n",
    "    device = torch.device('cuda') if torch.cuda.is_available() else 'cpu'\n",
    "    \n",
    "    model.to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(params=model.parameters(), lr=learning_rate)\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        \n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        \n",
    "        for i, batch in enumerate(data_loader):\n",
    "            inputs, lengths, targets = batch\n",
    "            inputs, targets = (inputs.to(device).long(), targets.to(device).long())\n",
    "            lengths = lengths.cpu()\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs, lengths)\n",
    "            \n",
    "            loss = criterion(outputs, targets)\n",
    "            loss.backward()\n",
    "            \n",
    "            optimizer.step()\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            \n",
    "        avg_loss = total_loss / len(data_loader)\n",
    "        \n",
    "        print(\n",
    "            f\"Epoch: {epoch+1} / {n_epochs}  |  loss: {avg_loss:.4f}\"\n",
    "        )"
   ],
   "id": "e1c873ad8fd34561",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def test_model(model, data_loader):\n",
    "\n",
    "    device = torch.device('cuda') if torch.cuda.is_available() else 'cpu'\n",
    "    model.to(device)\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "\n",
    "    with (torch.no_grad()):\n",
    "        for inputs, lengths, targets in data_loader:\n",
    "            inputs, targets = inputs.to(device).long(), targets.to(device).long()\n",
    "            lengths = lengths.cpu()\n",
    "            if 0 in lengths:\n",
    "                print(lengths)\n",
    "            \n",
    "            \n",
    "            outputs = model(inputs, lengths)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "            y_true.extend(targets.cpu().numpy())\n",
    "            y_pred.extend(predicted.cpu().numpy())\n",
    "\n",
    "    return y_true, y_pred"
   ],
   "id": "929f4b08e32ef326",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# tRAINING",
   "id": "46037c0a6fe88292"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "rnn_model = RNN(vocab_size=len(word_to_idx),\n",
    "                embed_size=256,\n",
    "                hidden_size=256,\n",
    "                dropout_rate=0,\n",
    "                n_layers=1,\n",
    "                output_size=42)"
   ],
   "id": "48762a124306006b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "train_model(\n",
    "    model=rnn_model,\n",
    "    data_loader=train_loader,\n",
    "    n_epochs=10,\n",
    "    learning_rate=0.001)"
   ],
   "id": "82ee4f3831b7dcc0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "y_true, y_pred = test_model(model=rnn_model, data_loader=test_loader)",
   "id": "f4f3f3cd179e159",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "print(classification_report(y_true, y_pred, target_names=category_to_label))"
   ],
   "id": "f49f492c2466140a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "fig = plt.figure(figsize=(20, 20))\n",
    "sb.heatmap(cm, cbar=False, cmap='Greys', annot=False, fmt='d')"
   ],
   "id": "2cc83a9d0b0f3856",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
